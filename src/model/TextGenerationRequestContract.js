/*
 * Woolball AI Network API
 * **Transform idle browsers into a powerful distributed AI inference network**  For detailed examples and model lists, visit our [GitHub repository](https://github.com/woolball-xyz/woolball-server).
 *
 * OpenAPI spec version: v1
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 *
 * Swagger Codegen version: 3.0.71
 *
 * Do not edit the class manually.
 *
 */
import ApiClient from '../ApiClient';

/**
 * The TextGenerationRequestContract model module.
 * @module model/TextGenerationRequestContract
 * @version v1
 */
export default class TextGenerationRequestContract {
  /**
   * Constructs a new <code>TextGenerationRequestContract</code>.
   * @alias module:model/TextGenerationRequestContract
   * @class
   * @param provider {module:model/TextGenerationRequestContract.ProviderEnum} The AI provider to use
   * @param model {String} The AI model to use for processing
   * @param input {String} Input text or messages for generation
   */
  constructor(provider, model, input) {
    this.provider = provider;
    this.model = model;
    this.input = input;
  }

  /**
   * Constructs a <code>TextGenerationRequestContract</code> from a plain JavaScript object, optionally creating a new instance.
   * Copies all relevant properties from <code>data</code> to <code>obj</code> if supplied or a new instance if not.
   * @param {Object} data The plain JavaScript object bearing properties of interest.
   * @param {module:model/TextGenerationRequestContract} obj Optional instance to populate.
   * @return {module:model/TextGenerationRequestContract} The populated <code>TextGenerationRequestContract</code> instance.
   */
  static constructFromObject(data, obj) {
    if (data) {
      obj = obj || new TextGenerationRequestContract();
      if (data.hasOwnProperty('provider'))
        obj.provider = ApiClient.convertToType(data['provider'], 'String');
      if (data.hasOwnProperty('model'))
        obj.model = ApiClient.convertToType(data['model'], 'String');
      if (data.hasOwnProperty('input'))
        obj.input = ApiClient.convertToType(data['input'], 'String');
      if (data.hasOwnProperty('top_k'))
        obj.topK = ApiClient.convertToType(data['top_k'], 'Number');
      if (data.hasOwnProperty('top_p'))
        obj.topP = ApiClient.convertToType(data['top_p'], 'Number');
      if (data.hasOwnProperty('temperature'))
        obj.temperature = ApiClient.convertToType(data['temperature'], 'Number');
      if (data.hasOwnProperty('repetition_penalty'))
        obj.repetitionPenalty = ApiClient.convertToType(data['repetition_penalty'], 'Number');
      if (data.hasOwnProperty('dtype'))
        obj.dtype = ApiClient.convertToType(data['dtype'], 'String');
      if (data.hasOwnProperty('max_length'))
        obj.maxLength = ApiClient.convertToType(data['max_length'], 'Number');
      if (data.hasOwnProperty('max_new_tokens'))
        obj.maxNewTokens = ApiClient.convertToType(data['max_new_tokens'], 'Number');
      if (data.hasOwnProperty('min_length'))
        obj.minLength = ApiClient.convertToType(data['min_length'], 'Number');
      if (data.hasOwnProperty('min_new_tokens'))
        obj.minNewTokens = ApiClient.convertToType(data['min_new_tokens'], 'Number');
      if (data.hasOwnProperty('do_sample'))
        obj.doSample = ApiClient.convertToType(data['do_sample'], 'Boolean');
      if (data.hasOwnProperty('num_beams'))
        obj.numBeams = ApiClient.convertToType(data['num_beams'], 'Number');
      if (data.hasOwnProperty('no_repeat_ngram_size'))
        obj.noRepeatNgramSize = ApiClient.convertToType(data['no_repeat_ngram_size'], 'Number');
      if (data.hasOwnProperty('context_window_size'))
        obj.contextWindowSize = ApiClient.convertToType(data['context_window_size'], 'Number');
      if (data.hasOwnProperty('sliding_window_size'))
        obj.slidingWindowSize = ApiClient.convertToType(data['sliding_window_size'], 'Number');
      if (data.hasOwnProperty('attention_sink_size'))
        obj.attentionSinkSize = ApiClient.convertToType(data['attention_sink_size'], 'Number');
      if (data.hasOwnProperty('frequency_penalty'))
        obj.frequencyPenalty = ApiClient.convertToType(data['frequency_penalty'], 'Number');
      if (data.hasOwnProperty('presence_penalty'))
        obj.presencePenalty = ApiClient.convertToType(data['presence_penalty'], 'Number');
      if (data.hasOwnProperty('bos_token_id'))
        obj.bosTokenId = ApiClient.convertToType(data['bos_token_id'], 'Number');
      if (data.hasOwnProperty('max_tokens'))
        obj.maxTokens = ApiClient.convertToType(data['max_tokens'], 'Number');
      if (data.hasOwnProperty('random_seed'))
        obj.randomSeed = ApiClient.convertToType(data['random_seed'], 'Number');
    }
    return obj;
  }
}

/**
 * Allowed values for the <code>provider</code> property.
 * @enum {String}
 * @readonly
 */
TextGenerationRequestContract.ProviderEnum = {
  /**
   * value: "transformers"
   * @const
   */
  transformers: "transformers",

  /**
   * value: "webllm"
   * @const
   */
  webllm: "webllm",

  /**
   * value: "mediapipe"
   * @const
   */
  mediapipe: "mediapipe"
};
/**
 * The AI provider to use
 * @member {module:model/TextGenerationRequestContract.ProviderEnum} provider
 */
TextGenerationRequestContract.prototype.provider = undefined;

/**
 * The AI model to use for processing
 * @member {String} model
 */
TextGenerationRequestContract.prototype.model = undefined;

/**
 * Input text or messages for generation
 * @member {String} input
 */
TextGenerationRequestContract.prototype.input = undefined;

/**
 * The number of highest probability vocabulary tokens to keep for top-k-filtering
 * @member {Number} topK
 */
TextGenerationRequestContract.prototype.topK = undefined;

/**
 * If set to float < 1, only the smallest set of most probable tokens with probabilities that add up to top_p or higher are kept for generation
 * @member {Number} topP
 */
TextGenerationRequestContract.prototype.topP = undefined;

/**
 * The value used to modulate the next token probabilities
 * @member {Number} temperature
 */
TextGenerationRequestContract.prototype.temperature = undefined;

/**
 * Parameter for repetition penalty. 1.0 means no penalty
 * @member {Number} repetitionPenalty
 */
TextGenerationRequestContract.prototype.repetitionPenalty = undefined;

/**
 * Quantization level (e.g., 'fp16', 'q4', 'q8') - Transformers only
 * @member {String} dtype
 */
TextGenerationRequestContract.prototype.dtype = undefined;

/**
 * Maximum length the generated tokens can have - Transformers only
 * @member {Number} maxLength
 */
TextGenerationRequestContract.prototype.maxLength = undefined;

/**
 * Maximum number of tokens to generate - Transformers only
 * @member {Number} maxNewTokens
 */
TextGenerationRequestContract.prototype.maxNewTokens = undefined;

/**
 * Minimum length of the sequence to be generated - Transformers only
 * @member {Number} minLength
 */
TextGenerationRequestContract.prototype.minLength = undefined;

/**
 * Minimum numbers of tokens to generate - Transformers only
 * @member {Number} minNewTokens
 */
TextGenerationRequestContract.prototype.minNewTokens = undefined;

/**
 * Whether to use sampling - Transformers only
 * @member {Boolean} doSample
 */
TextGenerationRequestContract.prototype.doSample = undefined;

/**
 * Number of beams for beam search - Transformers only
 * @member {Number} numBeams
 */
TextGenerationRequestContract.prototype.numBeams = undefined;

/**
 * If > 0, all ngrams of that size can only occur once - Transformers only
 * @member {Number} noRepeatNgramSize
 */
TextGenerationRequestContract.prototype.noRepeatNgramSize = undefined;

/**
 * Size of the context window for the model - WebLLM only
 * @member {Number} contextWindowSize
 */
TextGenerationRequestContract.prototype.contextWindowSize = undefined;

/**
 * Size of the sliding window for attention - WebLLM only
 * @member {Number} slidingWindowSize
 */
TextGenerationRequestContract.prototype.slidingWindowSize = undefined;

/**
 * Size of the attention sink - WebLLM only
 * @member {Number} attentionSinkSize
 */
TextGenerationRequestContract.prototype.attentionSinkSize = undefined;

/**
 * Penalty for token frequency - WebLLM only
 * @member {Number} frequencyPenalty
 */
TextGenerationRequestContract.prototype.frequencyPenalty = undefined;

/**
 * Penalty for token presence - WebLLM only
 * @member {Number} presencePenalty
 */
TextGenerationRequestContract.prototype.presencePenalty = undefined;

/**
 * Beginning of sequence token ID - WebLLM only
 * @member {Number} bosTokenId
 */
TextGenerationRequestContract.prototype.bosTokenId = undefined;

/**
 * Maximum number of tokens to generate - MediaPipe only
 * @member {Number} maxTokens
 */
TextGenerationRequestContract.prototype.maxTokens = undefined;

/**
 * Random seed for reproducible results - MediaPipe only
 * @member {Number} randomSeed
 */
TextGenerationRequestContract.prototype.randomSeed = undefined;


/*
 * Woolball AI Network API
 * **Transform idle browsers into a powerful distributed AI inference network**  For detailed examples and model lists, visit our [GitHub repository](https://github.com/woolball-xyz/woolball-server).
 *
 * OpenAPI spec version: v1
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 *
 * Swagger Codegen version: 3.0.71
 *
 * Do not edit the class manually.
 *
 */
import ApiClient from "../ApiClient";
import STTChunk from '../model/STTChunk';

/**
* SpeechRecognition service.
* @module api/SpeechRecognitionApi
* @version v1
*/
export default class SpeechRecognitionApi {

    /**
    * Constructs a new SpeechRecognitionApi. 
    * @alias module:api/SpeechRecognitionApi
    * @class
    * @param {module:ApiClient} [apiClient] Optional API client implementation to use,
    * default to {@link module:ApiClient#instanc
    e} if unspecified.
    */
    constructor(apiClient) {
        this.apiClient = apiClient || ApiClient.instance;
    }

    /**
     * Callback function to receive the result of the speechToText operation.
     * @callback moduleapi/SpeechRecognitionApi~speechToTextCallback
     * @param {String} error Error message, if any.
     * @param {Array.<module:model/STTChunk>{ data The data returned by the service call.
     * @param {String} response The complete HTTP response.
     */

    /**
     * Speech Recognition (Speech-to-Text)
     * Convert audio files to text using Whisper models. Supports MP3, WAV, M4A and other audio formats.
     * @param {String} model 
     * @param {String} dtype 
     * @param {Object} input 
     * @param {String} returnTimestamps 
     * @param {Boolean} stream 
     * @param {Number} chunkLengthS 
     * @param {Number} strideLengthS 
     * @param {Boolean} forceFullSequences 
     * @param {String} language 
     * @param {String} task 
     * @param {Number} numFrames 
     * @param {module:api/SpeechRecognitionApi~speechToTextCallback} callback The callback function, accepting three arguments: error, data, response
     * data is of type: {@link <&vendorExtensions.x-jsdoc-type>}
     */
    speechToText(model, dtype, input, returnTimestamps, stream, chunkLengthS, strideLengthS, forceFullSequences, language, task, numFrames, callback) {
      
      let postBody = null;
      // verify the required parameter 'model' is set
      if (model === undefined || model === null) {
        throw new Error("Missing the required parameter 'model' when calling speechToText");
      }
      // verify the required parameter 'dtype' is set
      if (dtype === undefined || dtype === null) {
        throw new Error("Missing the required parameter 'dtype' when calling speechToText");
      }
      // verify the required parameter 'input' is set
      if (input === undefined || input === null) {
        throw new Error("Missing the required parameter 'input' when calling speechToText");
      }
      // verify the required parameter 'returnTimestamps' is set
      if (returnTimestamps === undefined || returnTimestamps === null) {
        throw new Error("Missing the required parameter 'returnTimestamps' when calling speechToText");
      }
      // verify the required parameter 'stream' is set
      if (stream === undefined || stream === null) {
        throw new Error("Missing the required parameter 'stream' when calling speechToText");
      }
      // verify the required parameter 'chunkLengthS' is set
      if (chunkLengthS === undefined || chunkLengthS === null) {
        throw new Error("Missing the required parameter 'chunkLengthS' when calling speechToText");
      }
      // verify the required parameter 'strideLengthS' is set
      if (strideLengthS === undefined || strideLengthS === null) {
        throw new Error("Missing the required parameter 'strideLengthS' when calling speechToText");
      }
      // verify the required parameter 'forceFullSequences' is set
      if (forceFullSequences === undefined || forceFullSequences === null) {
        throw new Error("Missing the required parameter 'forceFullSequences' when calling speechToText");
      }
      // verify the required parameter 'language' is set
      if (language === undefined || language === null) {
        throw new Error("Missing the required parameter 'language' when calling speechToText");
      }
      // verify the required parameter 'task' is set
      if (task === undefined || task === null) {
        throw new Error("Missing the required parameter 'task' when calling speechToText");
      }
      // verify the required parameter 'numFrames' is set
      if (numFrames === undefined || numFrames === null) {
        throw new Error("Missing the required parameter 'numFrames' when calling speechToText");
      }

      let pathParams = {
        
      };
      let queryParams = {
        
      };
      let headerParams = {
        
      };
      let formParams = {
        'model': model,'dtype': dtype,'input': input,'return_timestamps': returnTimestamps,'stream': stream,'chunk_length_s': chunkLengthS,'stride_length_s': strideLengthS,'force_full_sequences': forceFullSequences,'language': language,'task': task,'num_frames': numFrames
      };

      let authNames = [];
      let contentTypes = ['multipart/form-data'];
      let accepts = ['application/json'];
      let returnType = [STTChunk];

      return this.apiClient.callApi(
        '/api/v1/speech-recognition', 'POST',
        pathParams, queryParams, headerParams, formParams, postBody,
        authNames, contentTypes, accepts, returnType, callback
      );
    }

}